[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "1 1.\n1. expected value:\nThe probabilities are not given. So lets assume that the probabilities are equal. So a normal average function from R can be used.\n\n# Import data\nrandom_vars &lt;- readRDS(\"../../assignment_data/random_vars.rds\")\n\n\n# Calculate Expectations, Variances, and Standard Deviations\nexpectation_age &lt;- mean(random_vars$age)\nexpectation_income &lt;- mean(random_vars$income)\nvariance_age &lt;- var(random_vars$age)\nvariance_income &lt;- var(random_vars$income)\nsd_age &lt;- sd(random_vars$age)\nsd_income &lt;- sd(random_vars$income)\n\n\n# Print results\ncat(\n  \"Expectation Age =\", expectation_age, \"\\n\",\n  \"Expectation Income =\", expectation_income, \"\\n\",\n  \"Variance Age =\", variance_age, \"\\n\",\n  \"Variance Income =\", variance_income, \"\\n\",\n  \"SD Age =\", sd_age, \"\\n\",\n  \"SD Income =\", sd_income, \"\\n\"\n)\n\n#&gt; Expectation Age = 33.471 \n#&gt;  Expectation Income = 3510.731 \n#&gt;  Variance Age = 340.6078 \n#&gt;  Variance Income = 8625646 \n#&gt;  SD Age = 18.45556 \n#&gt;  SD Income = 2936.945\n\n\n\n\n2 2.\nExplain, if it makes sense to compare the standard deviations.\n\nA standard deviation of 18.455 for “age” indicates moderate variability in the ages of the 1,000 individuals. Similarly, a standard deviation of 2,936.945 for “income” suggests significant income variability among the same group.\n\nThe standard deviation can be a useful descriptive statistic to understand the dispersion of data points within each variable. But, it doesn’t describe the nature of the relationship between age and income. To understand the relationship, covariance and correlation should be used.\n\n\n3 3.\n\n# Calculate covariance and correlation\ncovariance_result &lt;- cov(random_vars$age, random_vars$income)\ncorrelation_result &lt;- cor(random_vars$age, random_vars$income)\n\n\n# Print results\ncat(\"Covariance =\", covariance_result, \"\\nCorrelation =\", correlation_result, \"\\n\")\n\n#&gt; Covariance = 29700.15 \n#&gt; Correlation = 0.5479432\n\n\n\n\n4 4.\nWhat measure is easier to interpret? Please discuss your interpretation.\n\nCorrelation is a more robust approach for assessing the relationship between two sets of data. A positive correlation coefficient indicates that when one variable increases, the other tends to increase, whereas a negative correlation coefficient signifies that as one variable increases, the other typically decreases. Correlation coefficients range between -1 and 1, providing a standardized measure. Unlike covariance, which conveys strength and direction, correlation offers a normalized strength and direction, making it a more accessible and efficient metric for interpretation.\n\n\n5 5.\nCompute the conditional expected value for:\n\n\n# Calculate the conditional expected values\nexpected_value_age18andBelow &lt;- mean(subset(random_vars, age &lt;= 18)$income)\nexpected_value_age18_65 &lt;- mean(subset(random_vars, age &gt;= 18 & age &lt; 65)$income)\nexpected_value_age65andAbove &lt;- mean(subset(random_vars, age &gt;= 65)$income)\n\n# Print results\ncat(\n  \"Expected value E[income|age≤18]:\", expected_value_age18andBelow, \"\\n\",\n  \"Expected value E[income|age ∈ [18,65)]:\", expected_value_age18_65, \"\\n\",\n  \"Expected value E[income|age≥65]:\", expected_value_age65andAbove, \"\\n\"\n)\n\n#&gt; Expected value E[income|age≤18]: 389.6074 \n#&gt;  Expected value E[income|age ∈ [18,65)]: 4685.734 \n#&gt;  Expected value E[income|age≥65]: 1777.237"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "1 Example of Spur Correlation\nSource:\nhttps://tylervigen.com/spurious-correlations\n\n# Provided data\nyears &lt;- c(1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009)\nus_spending &lt;- c(18.079, 18.594, 19.753, 20.734, 20.831, 23.029, 23.597, 23.584, 25.525, 27.731, 29.449)\nsuicides &lt;- c(5427, 5688, 6198, 6462, 6635, 7336, 7248, 7491, 8161, 8578, 9000)\n\n# Create a data frame\ndata &lt;- data.frame(Year = years, US_Spending = us_spending, Suicides = suicides)\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n#&gt; Warning: Paket 'ggplot2' wurde unter R Version 4.3.2 erstellt\n\n# scale the second argument\nmyScale &lt;- 300\n\n# Create a plot with two y-axes\nplot &lt;- ggplot(data, aes(x = Year)) +\n  geom_line(aes(y = Suicides, color = \"Suicides\"), linewidth = 1) +\n  geom_line(aes(y = US_Spending * myScale, color = \"US Spending\"), linewidth = 1) +\n  scale_y_continuous(\n    name = \"Suicides in US\",\n    sec.axis = sec_axis(~./myScale, name = \"US Spending in Billion $\")\n  ) +\n  labs(\n    x = \"Year\",\n    title = \"Year vs. Suicides and US Spending\"\n  ) +\n  scale_color_manual(values = c(\"Suicides\" = \"blue\", \"US Spending\" = \"red\")) +\n  theme_minimal()\n\n# Show the plot\nprint(plot)\n\n\n\n\n\n\n\n# Calculate the correlation between Suicides and US Spending\ncor(suicides, us_spending)\n\n#&gt; [1] 0.9920817"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; Warning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'ggplot2' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'dplyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\n\n#&gt; Warning: Paket 'dagitty' wurde unter R Version 4.3.2 erstellt\n\nlibrary(ggdag)\n\n#&gt; Warning: Paket 'ggdag' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(MatchIt)\n\n#&gt; Warning: Paket 'MatchIt' wurde unter R Version 4.3.2 erstellt\n\nlibrary(dplyr)\n\nrand_enc &lt;- readRDS(\"../../assignment_data/rand_enc.rds\")"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; Warning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'ggplot2' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'dplyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\n\n#&gt; Warning: Paket 'dagitty' wurde unter R Version 4.3.2 erstellt\n\nlibrary(ggdag)\n\n#&gt; Warning: Paket 'ggdag' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(MatchIt)\n\n#&gt; Warning: Paket 'MatchIt' wurde unter R Version 4.3.2 erstellt\n\nlibrary(dplyr)\n\nmembership &lt;- readRDS(\"../../assignment_data/membership.rds\")"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "DAG",
    "section": "",
    "text": "1 1.\n\n# Load packages\nlibrary(tidyverse)\n\n#&gt; Warning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'ggplot2' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'dplyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\n\n#&gt; Warning: Paket 'dagitty' wurde unter R Version 4.3.2 erstellt\n\nlibrary(ggdag)\n\n#&gt; Warning: Paket 'ggdag' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nparkingDAG &lt;- dagify(\n  X ~ Z,\n  Y ~ Z,\n  Y ~ X,\n  coords = list(x = c(Y = 3, Z = 2, X = 1),\n                y = c(Y = 0, Z = 1, X = 0)),\n  labels = list(X = \"Parking Spot\",\n                Y = \"Sales\", \n                Z = \"Location\")\n)\n\n# Plot DAG\nggdag(parkingDAG) +\n  theme_dag_gray() + # custom theme, can be left out\n  geom_dag_point(color = \"lightgreen\") +\n  geom_dag_text(color = \"red\") +\n  geom_dag_edges(edge_color = \"blue\") +\n  geom_dag_label_repel(aes(label = label))\n\n\n\n\n\n\n\n\n\n\n2 2.\nIn the data, you find three variables: satisfaction, follow_ups and subscription. Perform the following steps:\n\nregress satisfaction on follow_ups\n\n\ncustomer_sat &lt;- readRDS(\"../../assignment_data/customer_sat.rds\")\nlm_followUps &lt;- lm(satisfaction ~ follow_ups, data = customer_sat)\nsummary(lm_followUps, digits = 3)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\n\nregress satisfaction on follow_ups and account for subscription\n\nlm_all &lt;- lm(satisfaction ~., data = customer_sat)\nsummary(lm_all, digits = 3)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ ., data = customer_sat)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\n\n3 3.\nIn the first table, the analysis shows that follow-ups have a very low p-value, indicating a significant impact on satisfaction. The negative estimate suggests that, on average, more follow-ups are associated with lower satisfaction scores.\n\nHowever, upon considering the new regression data, it becomes evident that the subscription plan seems to exert a comparatively stronger impact on satisfaction than follow-ups. Specifically, having a premium or premium plus subscription is associated with higher satisfaction, as indicated by their positive estimates. The sign of the follow-ups estimate has also changed, now suggesting that more follow-ups are associated with higher satisfaction.\n\nThis shift in estimates implies that the new subscription variable acts as a confounding variable. To accurately understand the relationship between follow-ups and satisfaction, it becomes essential to condition on the subscription variable. In other words, to draw meaningful conclusions, it is crucial to compare data for the same type of subscription, ensuring that the impact of follow-ups on satisfaction is assessed within each subscription category.\n\n\n\n4 4.\n\ndf &lt;- as_tibble(customer_sat)\n\n# Not conditioning on subscription\nnot_cond &lt;- ggplot(df, aes(x = follow_ups, y = satisfaction)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = F)\n\n\n# Conditioning on subscription  \ncond &lt;- ggplot(df, aes(x = follow_ups, y = satisfaction, color = subscription)) +\n  geom_point(alpha = .8) +\n  stat_smooth(method = \"lm\", se = F) +\n  theme(legend.position = \"right\")\n\nnot_cond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\ncond\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# DAG\n\nsatisf_DAG &lt;- dagify(\n  X ~ Z,\n  Y ~ Z,\n  Y ~ X,\n  coords = list(x = c(Y = 3, Z = 2, X = 1),\n                y = c(Y = 0, Z = 1, X = 0)),\n  labels = list(X = \"Follow ups\",\n                Y = \"Satisfaction\", \n                Z = \"Subscription\")\n)\n# Plot DAG\nggdag(satisf_DAG) +\n  theme_dag_gray() + # custom theme, can be left out\n  geom_dag_point(color = \"lightgreen\") +\n  geom_dag_text(color = \"red\") +\n  geom_dag_edges(edge_color = \"blue\") +\n  geom_dag_label_repel(aes(label = label))"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "library(dplyr)\n\n#&gt; Warning: Paket 'dplyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; \n#&gt; Attache Paket: 'dplyr'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\nlibrary(tidyverse)\n\n#&gt; Warning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'ggplot2' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ forcats   1.0.0     ✔ readr     2.1.4\n#&gt; ✔ ggplot2   3.4.4     ✔ stringr   1.5.0\n#&gt; ✔ lubridate 1.9.3     ✔ tibble    3.2.1\n#&gt; ✔ purrr     1.0.2     ✔ tidyr     1.3.0\n\n\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nabtest_online &lt;- readRDS(\"../../assignment_data/abtest_online.rds\")\n\n\n1 1.\n\nlibrary(dplyr)\n# Group by treatment group and compute average outcome\nabtest_online %&gt;%\n  group_by(chatbot) %&gt;%\n  summarise(mean_prev_visit = mean(previous_visit))\n\n\n\n  \n\n\n\n\n# \nabtest_online %&gt;%\n  group_by(chatbot) %&gt;%\n  summarise(mean_mobile_device = mean(mobile_device))\n\n\n\n  \n\n\n\nHere, mean previous visit and mean mobile device user is calculated for the control and treatment group separately which are differentiated according to the chatbot. The mean values are not that different which means the covariates are balanced across the groups. It can also be seen in the plot below:\n\ndf &lt;- as_tibble(abtest_online)\n\n# Plotting boxplots for mobile_device and previous_visit across chatbot groups\ncovariate_balance_plot &lt;- ggplot(df, aes(x = chatbot, y = previous_visit, fill = mobile_device)) +\n  geom_boxplot() +\n  labs(title = \"Covariate Balance Check\",\n       x = \"Chatbot\",\n       y = \"Previous Visit\") +\n  theme_minimal()\n\n# Print the plot\nprint(covariate_balance_plot)\n\n\n\n\n\n\n\n\n\ndf &lt;- as_tibble(abtest_online)\ncompare_visits &lt;- \n  ggplot(df, \n         aes(x = chatbot, \n             y = previous_visit, \n             color = as.factor(chatbot))) +\n  stat_summary(geom = \"errorbar\", \n               width = .5,\n               fun.data = \"mean_se\", \n               fun.args = list(mult=1.96),\n               show.legend = F) +\n  labs(x = \"chatbot\", y = \"previous_visit\", title = \"Difference in previous_visit\")\n\n\n\ncompare_devices &lt;- \n  ggplot(df, \n         aes(x = chatbot, \n             y = mobile_device, \n             color = as.factor(chatbot))) +\n  stat_summary(geom = \"errorbar\", \n               width = .5,\n               fun.data = \"mean_se\", \n               fun.args = list(mult=1.96),\n               show.legend = F) +\n  labs(x = \"chatbot\", y = \"mobile_device\", title = \"Difference in mobile_device\")\n\n\ncompare_purchase &lt;- \n  ggplot(df, \n         aes(x = chatbot, \n             y = purchase_amount, \n             color = as.factor(chatbot))) +\n  stat_summary(geom = \"errorbar\", \n               width = .5,\n               fun.data = \"mean_se\", \n               fun.args = list(mult=1.96),\n               show.legend = F) +\n  labs(x = \"chatbot\", y = \"purchase_amount\", title = \"Difference in purchase_amount\")\n\ncompare_visits\n\n\n\n\n\n\n\ncompare_devices\n\n\n\n\n\n\n\ncompare_purchase\n\n\n\n\n\n\n\n\n\n\n2 2.\n\nlm_chatbot &lt;- lm(purchase_amount ~ chatbot, data = abtest_online)\nsummary(lm_chatbot, digits = 3)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot, data = abtest_online)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -16.702 -14.478  -9.626  13.922  64.648 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  16.7017     0.8374  19.944  &lt; 2e-16 ***\n#&gt; chatbotTRUE  -7.0756     1.1796  -5.998 2.79e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.65 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.0348, Adjusted R-squared:  0.03383 \n#&gt; F-statistic: 35.98 on 1 and 998 DF,  p-value: 2.787e-09\n\n\nUpon reviewing the linear regression results, it is evident that the ‘chatbot’ variable has a significantly low p-value, indicating its influence on ‘purchase_amount.’ The estimate for the treatment group (chatbot = TRUE) is negative, signifying a statistically significant negative impact on ‘purchase_amount.’ In practical terms, users exposed to the chatbot exhibit a lower purchase amount compared to those not exposed.\n\n\n3 3.\n\nlm_chatbot_mobile &lt;- lm(purchase_amount ~ chatbot * mobile_device, data = abtest_online)\n\nsummary(lm_chatbot_mobile)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = abtest_online)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                    16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbotTRUE                    -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_deviceTRUE              -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbotTRUE:mobile_deviceTRUE  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08\n\n\nThe p-value for chatbotTRUE:mobile_deviceTRUE is comparatively high. So it has less effect on the purchase amount.\nUsing the coefficients, CATE for mobile users is -0.1526\n\n\n4 4.\n\nlogistic_regg&lt;- glm(purchase ~ chatbot, family = binomial(link = 'logit'), data = abtest_online)\nsummary(logistic_regg)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = purchase ~ chatbot, family = binomial(link = \"logit\"), \n#&gt;     data = abtest_online)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.01613    0.08981  -0.180    0.857    \n#&gt; chatbotTRUE -0.98939    0.13484  -7.337 2.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1329.1  on 999  degrees of freedom\n#&gt; Residual deviance: 1273.3  on 998  degrees of freedom\n#&gt; AIC: 1277.3\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n# Extract the coefficient for chatbotTRUE\nodds_ratio &lt;- exp(coef(logistic_regg)[\"chatbotTRUE\"])\nodds_ratio\n\n#&gt; chatbotTRUE \n#&gt;   0.3718025\n\n\nThe negative coefficient for the presence of the chatbot implies, on average, a decrease in the odds of making a purchase. Specifically, the odds ratio of approximately 0.37 indicates that when the chatbot is present, the odds of making a purchase are reduced by about 63% compared to when the chatbot is absent. In other words, the chatbot is associated with a substantial decrease in the likelihood of making a purchase"
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "library(tidyverse)\n\n#&gt; Warning: Paket 'tidyverse' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'ggplot2' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'tidyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'purrr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'dplyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'forcats' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; Warning: Paket 'lubridate' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#&gt; ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dagitty)\n\n#&gt; Warning: Paket 'dagitty' wurde unter R Version 4.3.2 erstellt\n\nlibrary(ggdag)\n\n#&gt; Warning: Paket 'ggdag' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; \n#&gt; Attache Paket: 'ggdag'\n#&gt; \n#&gt; Das folgende Objekt ist maskiert 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(MatchIt)\n\n#&gt; Warning: Paket 'MatchIt' wurde unter R Version 4.3.2 erstellt\n\nlibrary(dplyr)\n\nhospdd &lt;- readRDS(\"../../assignment_data/hospdd.rds\")\n\n\n1 . Manually computing the mean satisfaction for treated and control hospitals before and after the treatment:\n\n# Manually compute differences\n# Step 1: Difference between treatment and control group BEFORE treatment\n# control group -&gt; hospital ID 19 and above\n# treatment group -&gt; hospital ID 18 or less\n# treatment begin : from month 4\nbefore_control_A &lt;- hospdd %&gt;%\n  filter(hospital &gt; 18, month &lt; 4) %&gt;% \n  pull(satis)\nbefore_treatment_A &lt;- hospdd %&gt;%\n  filter(hospital &lt;= 18, month &lt; 4) %&gt;% \n  pull(satis)\n\ndiff_before_A &lt;- mean(before_treatment_A) - mean(before_control_A)\n\n# Step 2: Difference between treatment and control group AFTER treatment\nafter_control_A &lt;- hospdd %&gt;%\n  filter(hospital &gt; 18, month &gt;= 4) %&gt;% \n  pull(satis)\nafter_treatment_A &lt;- hospdd %&gt;%\n  filter(hospital &lt;= 18, month &gt;= 4) %&gt;% \n  pull(satis)\n\ndiff_after_A &lt;- mean(after_treatment_A) - mean(after_control_A)\n\n# Step 3: Difference-in-differences. \ndiff_diff_A &lt;- diff_after_A - diff_before_A\ncat(\"Estimate: \", diff_diff_A)\n\n#&gt; Estimate:  0.8479879\n\n\n\n\n2 . Using a linear regression to compute the estimate\nIn this context, it is important to note that the variables “month” and “hospital” are categorical, and they are not continuous or ordinal variables. Therefore, it is advisable to apply the as.factor() function to ensure more accurate computations.\n\nsummary(lm(satis ~ procedure + as.factor(month) + as.factor(hospital), data = hospdd))\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ procedure + as.factor(month) + as.factor(hospital), \n#&gt;     data = hospdd)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.1880 -0.4644  0.0067  0.4539  4.2921 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            3.1716566  0.0562207  56.414  &lt; 2e-16 ***\n#&gt; procedure              0.8479879  0.0342191  24.781  &lt; 2e-16 ***\n#&gt; as.factor(month)2     -0.0096077  0.0292119  -0.329 0.742244    \n#&gt; as.factor(month)3      0.0219686  0.0292119   0.752 0.452050    \n#&gt; as.factor(month)4     -0.0032839  0.0324936  -0.101 0.919504    \n#&gt; as.factor(month)5     -0.0094027  0.0324936  -0.289 0.772305    \n#&gt; as.factor(month)6     -0.0038375  0.0324936  -0.118 0.905990    \n#&gt; as.factor(month)7     -0.0111941  0.0324936  -0.345 0.730478    \n#&gt; as.factor(hospital)2   0.4085664  0.0772418   5.289 1.26e-07 ***\n#&gt; as.factor(hospital)3   0.5336248  0.0793384   6.726 1.88e-11 ***\n#&gt; as.factor(hospital)4   0.2275102  0.0739411   3.077 0.002099 ** \n#&gt; as.factor(hospital)5  -0.1453529  0.0739411  -1.966 0.049360 *  \n#&gt; as.factor(hospital)6   0.4478634  0.0739411   6.057 1.46e-09 ***\n#&gt; as.factor(hospital)7   1.4044164  0.0714559  19.654  &lt; 2e-16 ***\n#&gt; as.factor(hospital)8   0.0718758  0.0763186   0.942 0.346333    \n#&gt; as.factor(hospital)9  -1.5185150  0.0782447 -19.407  &lt; 2e-16 ***\n#&gt; as.factor(hospital)10  1.6828446  0.0772418  21.787  &lt; 2e-16 ***\n#&gt; as.factor(hospital)11  0.2209653  0.0763186   2.895 0.003799 ** \n#&gt; as.factor(hospital)12 -0.0953034  0.0782447  -1.218 0.223256    \n#&gt; as.factor(hospital)13  0.4955931  0.0754658   6.567 5.48e-11 ***\n#&gt; as.factor(hospital)14  0.2330426  0.0793384   2.937 0.003321 ** \n#&gt; as.factor(hospital)15 -0.1444935  0.0793384  -1.821 0.068613 .  \n#&gt; as.factor(hospital)16  1.4142680  0.0772418  18.310  &lt; 2e-16 ***\n#&gt; as.factor(hospital)17  0.4235429  0.0805362   5.259 1.49e-07 ***\n#&gt; as.factor(hospital)18  0.1532761  0.0938164   1.634 0.102346    \n#&gt; as.factor(hospital)19 -0.7453017  0.0811623  -9.183  &lt; 2e-16 ***\n#&gt; as.factor(hospital)20  0.0473874  0.0791140   0.599 0.549207    \n#&gt; as.factor(hospital)21  1.1943370  0.0836232  14.282  &lt; 2e-16 ***\n#&gt; as.factor(hospital)22  0.7993153  0.0823336   9.708  &lt; 2e-16 ***\n#&gt; as.factor(hospital)23  0.7017202  0.0811623   8.646  &lt; 2e-16 ***\n#&gt; as.factor(hospital)24 -0.3081260  0.0866402  -3.556 0.000378 ***\n#&gt; as.factor(hospital)25  0.6464736  0.0927258   6.972 3.40e-12 ***\n#&gt; as.factor(hospital)26  0.2142471  0.0791140   2.708 0.006783 ** \n#&gt; as.factor(hospital)27 -0.3986544  0.0766106  -5.204 2.01e-07 ***\n#&gt; as.factor(hospital)28  0.7119953  0.0836232   8.514  &lt; 2e-16 ***\n#&gt; as.factor(hospital)29  0.2485512  0.0800935   3.103 0.001921 ** \n#&gt; as.factor(hospital)30 -0.1679220  0.0953638  -1.761 0.078304 .  \n#&gt; as.factor(hospital)31  0.5120848  0.0791140   6.473 1.02e-10 ***\n#&gt; as.factor(hospital)32 -0.3233456  0.0800935  -4.037 5.47e-05 ***\n#&gt; as.factor(hospital)33 -0.4539752  0.0791140  -5.738 9.95e-09 ***\n#&gt; as.factor(hospital)34 -0.0004123  0.0746054  -0.006 0.995590    \n#&gt; as.factor(hospital)35  0.3541110  0.0766106   4.622 3.86e-06 ***\n#&gt; as.factor(hospital)36  2.1381425  0.0773811  27.631  &lt; 2e-16 ***\n#&gt; as.factor(hospital)37  0.1404036  0.0927258   1.514 0.130023    \n#&gt; as.factor(hospital)38 -0.0868060  0.0782129  -1.110 0.267093    \n#&gt; as.factor(hospital)39 -0.0234969  0.0823336  -0.285 0.775356    \n#&gt; as.factor(hospital)40  1.1215331  0.0782129  14.339  &lt; 2e-16 ***\n#&gt; as.factor(hospital)41 -0.1497346  0.0766106  -1.954 0.050681 .  \n#&gt; as.factor(hospital)42  0.8811369  0.0850508  10.360  &lt; 2e-16 ***\n#&gt; as.factor(hospital)43 -0.7724325  0.0811623  -9.517  &lt; 2e-16 ***\n#&gt; as.factor(hospital)44  0.0344120  0.0904337   0.381 0.703569    \n#&gt; as.factor(hospital)45 -0.2137495  0.0766106  -2.790 0.005283 ** \n#&gt; as.factor(hospital)46  0.0784915  0.0823336   0.953 0.340452    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7238 on 7315 degrees of freedom\n#&gt; Multiple R-squared:  0.5333, Adjusted R-squared:  0.5299 \n#&gt; F-statistic: 160.7 on 52 and 7315 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "\\[\\begin{align*}\nP(T \\cap S) &= P(T|S) \\cdot P(S) \\\\\n            &= 0.2 \\cdot 0.3 \\\\\n            &= 0.06\n\\end{align*}\\]\n\\[\\begin{align*}\nP(T \\cap \\overline{S}) &= P(T|\\overline{S}) \\cdot P(\\overline{S}) \\\\\n                       &= 0.6 \\cdot 0.7 \\\\\n                       &= 0.42\n\\end{align*}\\]\n\\[\\begin{align*}\nP(\\overline{T} \\cap S) &= P(\\overline{T}|{S}) \\cdot P({S}) \\\\\n                       &= 0.8 \\cdot 0.3 \\\\\n                       &= 0.24\n\\end{align*}\\]\n\\[\\begin{align*}\nP(\\overline{T} \\cap \\overline{S}) &= P(\\overline{T}|\\overline{S}) \\cdot P(\\overline{S}) \\\\\n                       &= 0.4 \\cdot 0.7 \\\\\n                       &= 0.28\n\\end{align*}\\]"
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "\n2.1 Header 2",
    "text": "2.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "1 1.\n\nlibrary(dplyr)\n\n#&gt; Warning: Paket 'dplyr' wurde unter R Version 4.3.2 erstellt\n\n\n#&gt; \n#&gt; Attache Paket: 'dplyr'\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; Die folgenden Objekte sind maskiert von 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\n# Read data\ncar_prices &lt;- readRDS(\"../../assignment_data/car_prices.rds\")\n\n# check dimensions\ndimensions &lt;- dim(car_prices)\n\n# Print the number of rows and columns\ncat(\n  \"Number of Rows     : \", dimensions[1], \"\\n\",\n  \"Number of Columns  : \", dimensions[2], \"\\n\"\n)\n\n#&gt; Number of Rows     :  181 \n#&gt;  Number of Columns  :  22\n\n\n\n\n2 2.\nDetailed Look at the data\n\n# overview with head() function\nhead(car_prices)\n\n\n\n  \n\n\n# quick summary\nsummary(car_prices,digits = 3)\n\n#&gt;   aspiration         doornumber          carbody           drivewheel       \n#&gt;  Length:181         Length:181         Length:181         Length:181        \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  enginelocation       wheelbase       carlength      carwidth      carheight   \n#&gt;  Length:181         Min.   : 86.6   Min.   :141   Min.   :60.3   Min.   :47.8  \n#&gt;  Class :character   1st Qu.: 94.5   1st Qu.:166   1st Qu.:64.0   1st Qu.:52.0  \n#&gt;  Mode  :character   Median : 96.5   Median :173   Median :65.4   Median :53.7  \n#&gt;                     Mean   : 98.2   Mean   :173   Mean   :65.7   Mean   :53.6  \n#&gt;                     3rd Qu.:100.4   3rd Qu.:180   3rd Qu.:66.5   3rd Qu.:55.5  \n#&gt;                     Max.   :120.9   Max.   :208   Max.   :72.3   Max.   :59.8  \n#&gt;    curbweight    enginetype        cylindernumber       enginesize \n#&gt;  Min.   :1488   Length:181         Length:181         Min.   : 61  \n#&gt;  1st Qu.:2122   Class :character   Class :character   1st Qu.: 98  \n#&gt;  Median :2410   Mode  :character   Mode  :character   Median :120  \n#&gt;  Mean   :2521                                         Mean   :127  \n#&gt;  3rd Qu.:2910                                         3rd Qu.:141  \n#&gt;  Max.   :4066                                         Max.   :326  \n#&gt;   fuelsystem          boreratio        stroke     compressionratio\n#&gt;  Length:181         Min.   :2.54   Min.   :2.07   Min.   : 7.00   \n#&gt;  Class :character   1st Qu.:3.15   1st Qu.:3.08   1st Qu.: 8.50   \n#&gt;  Mode  :character   Median :3.31   Median :3.23   Median : 9.00   \n#&gt;                     Mean   :3.32   Mean   :3.23   Mean   : 8.85   \n#&gt;                     3rd Qu.:3.59   3rd Qu.:3.40   3rd Qu.: 9.40   \n#&gt;                     Max.   :3.94   Max.   :4.17   Max.   :11.50   \n#&gt;    horsepower     peakrpm        citympg       highwaympg       price      \n#&gt;  Min.   : 48   Min.   :4200   Min.   :13.0   Min.   :16.0   Min.   : 5118  \n#&gt;  1st Qu.: 70   1st Qu.:4800   1st Qu.:19.0   1st Qu.:25.0   1st Qu.: 7609  \n#&gt;  Median : 95   Median :5200   Median :24.0   Median :30.0   Median : 9980  \n#&gt;  Mean   :106   Mean   :5182   Mean   :24.8   Mean   :30.5   Mean   :12999  \n#&gt;  3rd Qu.:116   3rd Qu.:5500   3rd Qu.:30.0   3rd Qu.:34.0   3rd Qu.:16430  \n#&gt;  Max.   :288   Max.   :6600   Max.   :49.0   Max.   :54.0   Max.   :45400\n\n# data types:\ncat(\"Data Types:\\n\", sapply(car_prices, class), \"\\n\")\n\n#&gt; Data Types:\n#&gt;  character character character character character numeric numeric numeric numeric numeric character character numeric character numeric numeric numeric numeric numeric numeric numeric numeric\n\n\nHow do numbers differ from strings regarding their data type?\nNumeric data in R can take the form of either integers or floating-point numbers, and they are primarily employed for mathematical calculations and numerical analysis. Conversely, strings represent character data, comprising sequences of characters that can include letters, digits, and symbols. In some cases, datasets may include categorical variables, which can be converted into numerical values using methods such as factorization with functions like as.factor().\n\n\n3 3.\nRun a linear regression. You want to explain what factors are relevant for the pricing of a car.\n\nUsing the lm() function,\n\nlm_all &lt;- lm(price ~ .,data = car_prices)\nsummary(lm_all, digits = 3)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = car_prices)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nExamining the summary, we can identify variables with low p-values, indicating their relevance to car pricing. Notably, factors such as peakrpm, stroke, enginesize, cylindernumber, and enginetype exhibit high relevance, as their p-values are substantially low, below 0.001. In contrast, features like carwidth and carbody show a comparatively lower impact on car prices, with p-values ranging between 0.001 and 0.01.The remaining regressors demonstrate a diminished influence on determining the car price.\n\n\n4 4.\nLet’s examine the regressor “peakrpm.” According to the summary, it is of numeric data type, ranging between 4200 to 6600.\n\nThe linear regression model provides a positive but modest estimate for “peakrpm.” This suggests that as the value of the regressor increases, the car price tends to increase, although not substantially. Specifically, for every one-unit increase in peakrpm, the car price increases by only 2.526 units. However, since the value of “peakrpm” varies in magnitudes of 1000, it can lead to changes in the car price on a similar scale.\n\nWhat’s noteworthy is that “peakrpm” holds statistical significance due to its low p-value. This indicates a strong relevance in determining the car’s price.\n\n\n5 5.\n\ncar_prices2 &lt;- car_prices %&gt;%\n  mutate(seat_heating = TRUE)\n\nmodel &lt;- lm(price ~ ., data = car_prices2)\nsummary(model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = car_prices2)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; seat_heatingTRUE             NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nSince all the values in the “seat_heating” variable are the same (TRUE), it implies there is no variability in that variable, and this lack of variability doesn’t influence the dependent variable. Intuitively, the estimate value should have been zero due to this perfect collinearity. However, the function returns NA for all the parameters because of the singularity."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "library(tidyverse)\nlibrary(rddensity)\n\ndf&lt;- readRDS(\"../../assignment_data/coupon.rds\")\n\n# Define cut-off\nc0 &lt;- 60\n\n# Density test\nrddd &lt;- rddensity(df$days_since_last, c = c0)\nsummary(rddd)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       5000\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           estimated\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 60                Left of c           Right of c          \n#&gt; Number of obs         3854                1146                \n#&gt; Eff. Number of obs    1486                734                 \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           31.203              31.915              \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                1.1559              0.2477\n\n\n#&gt; Warning in summary.CJMrddensity(rddd): There are repeated observations. Point\n#&gt; estimates and standard errors have been adjusted. Use option massPoints=FALSE\n#&gt; to suppress this feature.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 0.500                      20      20    1.0000\n#&gt; 1.000                      31      35    0.7122\n#&gt; 1.500                      44      47    0.8341\n#&gt; 2.000                      70      68    0.9322\n#&gt; 2.500                      92      89    0.8819\n#&gt; 3.000                     110     105    0.7851\n#&gt; 3.500                     123     118    0.7967\n#&gt; 4.000                     135     129    0.7584\n#&gt; 4.500                     148     142    0.7691\n#&gt; 5.000                     164     159    0.8239\n\n\n\n1 . Half the bandwidth:\n\n# Specify bandwidth\nbw_half &lt;- c0 + c(-5/2, 5/2)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw_half[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw_half[2])\n\n\ndf_bw_half &lt;- bind_rows(df_bw_above, df_bw_below)\ndim(df_bw_half)\n\n#&gt; [1] 181   4\n\n# [3.2] Local Average treatment effect (LATE) ----\n# Extract values for vertical lines to visualize local average treatment effect\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n#&gt; [1] \"LATE: 7.36\"\n\n# [4] Estimation ----\n# [4.1] Parametric ----\n# Compute coefficients for specified bandwidth.\nlm_bw_half &lt;- lm(purchase_after ~ days_since_last_centered + coupon, df_bw_half)\nsummary(lm_bw_half)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_after ~ days_since_last_centered + coupon, \n#&gt;     data = df_bw_half)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -10.9680  -2.2013   0.1676   2.1516   8.2567 \n#&gt; \n#&gt; Coefficients:\n#&gt;                          Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)               11.6612     0.5747  20.292  &lt; 2e-16 ***\n#&gt; days_since_last_centered   0.6883     0.3219   2.138   0.0339 *  \n#&gt; couponTRUE                 7.1679     1.0172   7.047 3.87e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.289 on 178 degrees of freedom\n#&gt; Multiple R-squared:  0.6622, Adjusted R-squared:  0.6584 \n#&gt; F-statistic: 174.5 on 2 and 178 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n2 . double the bandwidth\n\n# doubled bw\nbw_doubled &lt;- c0 + c(-10, 10)\n\n# Subsets below and above threshold in specified bandwidth\ndf_bw_below &lt;- df %&gt;% filter(days_since_last &gt;= bw_doubled[1] & days_since_last &lt; c0)\ndf_bw_above &lt;- df %&gt;% filter(days_since_last &gt;= c0 & days_since_last &lt;= bw_doubled[2])\n\ndf_bw_doubled &lt;- bind_rows(df_bw_above, df_bw_below)\ndim(df_bw_doubled)\n\n#&gt; [1] 629   4\n\n# [3.2] Local Average treatment effect (LATE) ----\n# Extract values for vertical lines to visualize local average treatment effect\nmodel_bw_below &lt;- lm(purchase_after ~ days_since_last, df_bw_below)\nmodel_bw_above &lt;- lm(purchase_after ~ days_since_last, df_bw_above)\n\ny0 &lt;- predict(model_bw_below, tibble(days_since_last = c0))\ny1 &lt;- predict(model_bw_above, tibble(days_since_last = c0))\n\nlate &lt;- y1 - y0\nsprintf(\"LATE: %.2f\", late)\n\n#&gt; [1] \"LATE: 9.51\"\n\n# [4] Estimation ----\n# [4.1] Parametric ----\n# Compute coefficients for specified bandwidth.\nlm_bw_doubled &lt;- lm(purchase_after ~ days_since_last_centered + coupon, df_bw_doubled)\nsummary(lm_bw_doubled)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_after ~ days_since_last_centered + coupon, \n#&gt;     data = df_bw_doubled)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -12.2718  -2.0858  -0.0003   2.0275  10.6749 \n#&gt; \n#&gt; Coefficients:\n#&gt;                          Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)              10.61700    0.27386  38.767   &lt;2e-16 ***\n#&gt; days_since_last_centered  0.01413    0.04255   0.332     0.74    \n#&gt; couponTRUE                9.51584    0.48628  19.569   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 3.115 on 626 degrees of freedom\n#&gt; Multiple R-squared:  0.7052, Adjusted R-squared:  0.7042 \n#&gt; F-statistic: 748.6 on 2 and 626 DF,  p-value: &lt; 2.2e-16\n\n\nBy taking half the bandwidth the number of data reduced to 181 and by doubling it, the number nearly doubled as well. The LATE and estimate value has decreased with the decreasing bandwidth and increased with the doubled bandwidth. The p-value of couponTRUE however has increased only for the smaller bandwidth.\n\n\n3 . Free Shipping\n\nfree_shipping&lt;- readRDS(\"../../assignment_data/shipping.rds\")\n\nlibrary(ggplot2)\n\n# Create a histogram\nggplot(free_shipping, aes(x = purchase_amount)) +\n  geom_histogram(binwidth = 4, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  geom_vline(xintercept = 30, linetype = \"dashed\", color = \"red\", linewidth = 0.5) +\n  labs(title = \"Distribution of Purchase Amounts\",\n       x = \"Purchase Amount (€)\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# density check:\nrd_shipping &lt;- rddensity(free_shipping$purchase_amount, c = 30)\nsummary(rd_shipping)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       6666\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           estimated\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 30                Left of c           Right of c          \n#&gt; Number of obs         3088                3578                \n#&gt; Eff. Number of obs    2221                1955                \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           22.909              20.394              \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                5.9855              0\n\n\n#&gt; Warning in summary.CJMrddensity(rd_shipping): There are repeated observations.\n#&gt; Point estimates and standard errors have been adjusted. Use option\n#&gt; massPoints=FALSE to suppress this feature.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 0.261                      20      26    0.4614\n#&gt; 0.522                      41      65    0.0250\n#&gt; 0.783                      62     107    0.0007\n#&gt; 1.043                      81     136    0.0002\n#&gt; 1.304                     100     169    0.0000\n#&gt; 1.565                     114     196    0.0000\n#&gt; 1.826                     132     227    0.0000\n#&gt; 2.087                     156     263    0.0000\n#&gt; 2.348                     173     298    0.0000\n#&gt; 2.609                     191     331    0.0000\n\n# Visually check continuity at running variable\nrd_shipping_plot &lt;- rdplotdensity(rd_shipping, free_shipping$purchase_amount, plotN = 100)\n\n\n\n\n\n\n\n\nThe histogram shows the sudden change in frequency at 30€. To check it more thoroughly, rddensity is used. It shows that the p-value is zero. Additionally, the rdplotdensity shows that there is no confidence intervals overlap. This means there is some kind of manipulation around the cut-off and RDD cannot be used to obtain valid results."
  },
  {
    "objectID": "content/01_journal/01_probability.html#assignment-i",
    "href": "content/01_journal/01_probability.html#assignment-i",
    "title": "Probability Theory",
    "section": "",
    "text": "\\[\\begin{align*}\nP(T \\cap S) &= P(T|S) \\cdot P(S) \\\\\n            &= 0.2 \\cdot 0.3 \\\\\n            &= 0.06\n\\end{align*}\\]\n\\[\\begin{align*}\nP(T \\cap \\overline{S}) &= P(T|\\overline{S}) \\cdot P(\\overline{S}) \\\\\n                       &= 0.6 \\cdot 0.7 \\\\\n                       &= 0.42\n\\end{align*}\\]\n\\[\\begin{align*}\nP(\\overline{T} \\cap S) &= P(\\overline{T}|{S}) \\cdot P({S}) \\\\\n                       &= 0.8 \\cdot 0.3 \\\\\n                       &= 0.24\n\\end{align*}\\]\n\\[\\begin{align*}\nP(\\overline{T} \\cap \\overline{S}) &= P(\\overline{T}|\\overline{S}) \\cdot P(\\overline{S}) \\\\\n                       &= 0.4 \\cdot 0.7 \\\\\n                       &= 0.28\n\\end{align*}\\]"
  },
  {
    "objectID": "content/01_journal/01_probability.html#assignment-ii",
    "href": "content/01_journal/01_probability.html#assignment-ii",
    "title": "Probability Theory",
    "section": "2 Assignment II",
    "text": "2 Assignment II\n1. What is the percentage of customers using all three devices? \n–&gt; 0.5 %\n2. What is the percentage of customers using at least two devices? \n–&gt; To calculate this, sum the percentages of customers using both Computer and Tablet, Tablet and Smartphone, Smartphone and Computer, and the percentage of customers using all three devices.\n3.3 + 7.3 + 8.8 + 0.5 = 19.9 %\n3. What is the percentage of customers using only one device?\n–&gt; It is the sum of the rest of the percentages.\n10 + 27.8 + 42.3 = 80.1 %"
  },
  {
    "objectID": "content/01_journal/01_probability.html#assignment-iii",
    "href": "content/01_journal/01_probability.html#assignment-iii",
    "title": "Probability Theory",
    "section": "3 Assignment III",
    "text": "3 Assignment III\nUsing Bayes Theorem:\n\\[\\begin{align*}\nP(A|B) &= \\frac{P(B|A) \\cdot P(A)}{P(B|A) \\cdot P(A) + P(B|\\overline{A}) \\cdot P(\\overline{A)}} \\\\\n&= \\frac{0.97 \\cdot 0.04}{0.97 \\cdot 0.04 + 0.01 \\cdot (1 - 0.04)} \\\\\n&\\approx 0.80165\n\\end{align*}\\]\n\n\n\n\\[\\begin{align*}\nP(\\overline{A}|B) &= \\frac{P(B|\\overline{A}) \\cdot P(\\overline{A)}}{P(B|\\overline{A}) \\cdot P(\\overline{A}) + P(B|A) \\cdot P(A)} \\\\\n&= \\frac{0.01 \\cdot (1 - 0.04)}{0.01 \\cdot (1 - 0.04) + 0.97 \\cdot 0.04} \\\\\n&\\approx 0.19835\n\\end{align*}\\]\nThese results show that in case the alarm is triggered, there is a possibility of about 80.165% that the product is flawless and a probability of 19.835% that the product is faulty."
  },
  {
    "objectID": "content/01_journal/09_iv.html#the-assumptions-that-can-be-partly-tested-check-whether-they-are-satisfied-by-either-computing-correlations-or-drawing-plots.",
    "href": "content/01_journal/09_iv.html#the-assumptions-that-can-be-partly-tested-check-whether-they-are-satisfied-by-either-computing-correlations-or-drawing-plots.",
    "title": "Instrumental Variables",
    "section": "3.1 .the assumptions that can be (partly) tested, check whether they are satisfied by either computing correlations or drawing plots.",
    "text": "3.1 .the assumptions that can be (partly) tested, check whether they are satisfied by either computing correlations or drawing plots.\n\n# Correlation matrix\ncor(rand_enc) %&gt;% round(2)\n\n#&gt;            rand_enc used_ftr time_spent\n#&gt; rand_enc       1.00     0.20       0.13\n#&gt; used_ftr       0.20     1.00       0.71\n#&gt; time_spent     0.13     0.71       1.00\n\n\nStable unit treatment value assumption: It is valid as the use of new feature by one user doesn’t affect the other.\n\nIndependence assumption:  There is no known confounding variable between Encouragement popup and the use of new feature or between the popup and the time spent.\n\nExclusion restriction: The instrument, encouragement popup does not directly affect the outcome time_spent but only through the treatment, the new feature.\n\nInstrument relevance: As seen from the correlation matrix, the instrument “rand_enc” and treatment variable “used_ftr” are correlated. However, the correlation is not so strong, only 0.2\n\nMonotonicity assumption: Instrument and treatment variables are compliers."
  },
  {
    "objectID": "content/01_journal/09_iv.html#argue-whether-instrumental-variable-estimation-is-an-adequate-procedure.",
    "href": "content/01_journal/09_iv.html#argue-whether-instrumental-variable-estimation-is-an-adequate-procedure.",
    "title": "Instrumental Variables",
    "section": "3.2 . Argue whether instrumental variable estimation is an adequate procedure.",
    "text": "3.2 . Argue whether instrumental variable estimation is an adequate procedure.\nThe necessary assumptions are fulfilled. The correlation between instrument and treatment variable is however not so high. So, it is important to interpret the results with caution and further exploration and potential refinement of the instrumental variable may be beneficial."
  },
  {
    "objectID": "content/01_journal/09_iv.html#compute-the-iv-estimate-using-2sls-and-compare-it-to-the-naive-estimate.",
    "href": "content/01_journal/09_iv.html#compute-the-iv-estimate-using-2sls-and-compare-it-to-the-naive-estimate.",
    "title": "Instrumental Variables",
    "section": "4.1 . Compute the IV estimate using 2SLS and compare it to the naive estimate.",
    "text": "4.1 . Compute the IV estimate using 2SLS and compare it to the naive estimate.\n\nlibrary(estimatr)\n\n#&gt; Warning: Paket 'estimatr' wurde unter R Version 4.3.2 erstellt\n\nmodel_iv &lt;- iv_robust(time_spent ~ used_ftr | rand_enc, data = rand_enc)\nsummary(model_iv)\n\n#&gt; \n#&gt; Call:\n#&gt; iv_robust(formula = time_spent ~ used_ftr | rand_enc, data = rand_enc)\n#&gt; \n#&gt; Standard error type:  HC2 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper   DF\n#&gt; (Intercept)   19.312     0.2248   85.89 0.000e+00   18.872    19.75 9998\n#&gt; used_ftr       9.738     0.5353   18.19 8.716e-73    8.689    10.79 9998\n#&gt; \n#&gt; Multiple R-squared:  0.4921 ,    Adjusted R-squared:  0.492 \n#&gt; F-statistic:   331 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\nThe estimate has reduced by about 1 unit and the p-value has significantly reduced as well."
  },
  {
    "objectID": "content/01_journal/07_matching.html#coarsened-exact-matching",
    "href": "content/01_journal/07_matching.html#coarsened-exact-matching",
    "title": "Matching and Subclassification",
    "section": "3.1 (Coarsened) Exact Matching :",
    "text": "3.1 (Coarsened) Exact Matching :\n\n# Load 'MatchIt' library\nlibrary(MatchIt)\n\n# Without specifying coarsening\n# (1) Matching\ncem &lt;- matchit(card ~ age + pre_avg_purch,\n               data = membership, \n               method = 'cem', \n               estimand = 'ATE')\n# Covariate balance\nsummary(cem)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + pre_avg_purch, data = membership, \n#&gt;     method = \"cem\", estimand = \"ATE\")\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 42.0331       39.1574          0.2136     1.1524    0.0438\n#&gt; pre_avg_purch       76.3938       66.0438          0.3962     1.0276    0.1092\n#&gt;               eCDF Max\n#&gt; age             0.0864\n#&gt; pre_avg_purch   0.1545\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 40.2869       40.2645          0.0017     1.0001    0.0016\n#&gt; pre_avg_purch       70.5402       70.1875          0.0135     0.9910    0.0044\n#&gt;               eCDF Max Std. Pair Dist.\n#&gt; age             0.0067          0.1224\n#&gt; pre_avg_purch   0.0133          0.1557\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All           5768.   4232.  \n#&gt; Matched (ESS) 5527.11 3928.04\n#&gt; Matched       5752.   4199.  \n#&gt; Unmatched       16.     33.  \n#&gt; Discarded        0.      0.\n\n# Use matched data\ndf_cem &lt;- match.data(cem)\n\n# (2) Estimation\nmodel_cem &lt;- lm(avg_purch  ~ card, data = df_cem, weights = weights)\nsummary(model_cem)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df_cem, weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -155.31  -20.74   -0.17   20.25  146.91 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  70.0474     0.3996  175.30   &lt;2e-16 ***\n#&gt; card         15.2687     0.6151   24.82   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 30.31 on 9949 degrees of freedom\n#&gt; Multiple R-squared:  0.05831,    Adjusted R-squared:  0.05822 \n#&gt; F-statistic: 616.1 on 1 and 9949 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/07_matching.html#nearest-neighbor-matching",
    "href": "content/01_journal/07_matching.html#nearest-neighbor-matching",
    "title": "Matching and Subclassification",
    "section": "3.2 Nearest-Neighbor Matching:",
    "text": "3.2 Nearest-Neighbor Matching:\n\n# (1) Matching\n# replace: one-to-one or one-to-many matching\nnn &lt;- matchit(card ~ age + pre_avg_purch,\n              data = membership,\n              method = \"nearest\", # changed\n              distance = \"mahalanobis\", # changed\n              replace = T)\n\n# Covariate Balance\nsummary(nn)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + pre_avg_purch, data = membership, \n#&gt;     method = \"nearest\", distance = \"mahalanobis\", replace = T)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 42.0331       39.1574          0.2064     1.1524    0.0438\n#&gt; pre_avg_purch       76.3938       66.0438          0.3936     1.0276    0.1092\n#&gt;               eCDF Max\n#&gt; age             0.0864\n#&gt; pre_avg_purch   0.1545\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 42.0331       42.0132          0.0014     1.0078    0.0011\n#&gt; pre_avg_purch       76.3938       76.3390          0.0021     1.0075    0.0011\n#&gt;               eCDF Max Std. Pair Dist.\n#&gt; age             0.0045          0.0202\n#&gt; pre_avg_purch   0.0057          0.0219\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All           5768.      4232\n#&gt; Matched (ESS) 2032.44    4232\n#&gt; Matched       2700.      4232\n#&gt; Unmatched     3068.         0\n#&gt; Discarded        0.         0\n\n# Use matched data\ndf_nn &lt;- match.data(nn)\n\n# (2) Estimation\nmodel_nn &lt;- lm(avg_purch ~ card, data = df_nn, weights = weights)\nsummary(model_nn)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df_nn, weights = weights)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -101.515  -21.159   -1.517   18.610  181.319 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  76.2067     0.5844  130.40   &lt;2e-16 ***\n#&gt; card         14.9524     0.7479   19.99   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 30.37 on 6930 degrees of freedom\n#&gt; Multiple R-squared:  0.05453,    Adjusted R-squared:  0.05439 \n#&gt; F-statistic: 399.7 on 1 and 6930 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/07_matching.html#inverse-probability-weightin",
    "href": "content/01_journal/07_matching.html#inverse-probability-weightin",
    "title": "Matching and Subclassification",
    "section": "3.3 Inverse Probability Weightin:",
    "text": "3.3 Inverse Probability Weightin:\n\nlibrary(dplyr)\n\n# (1) Propensity scores\nmodel_prop &lt;- glm(card ~ age + pre_avg_purch,\n                  data = membership,\n                  family = binomial(link = \"logit\"))\nsummary(model_prop)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = card ~ age + pre_avg_purch, family = binomial(link = \"logit\"), \n#&gt;     data = membership)\n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   -1.4121735  0.0723729 -19.512   &lt;2e-16 ***\n#&gt; age            0.0011734  0.0017758   0.661    0.509    \n#&gt; pre_avg_purch  0.0148181  0.0009263  15.996   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 13626  on 9999  degrees of freedom\n#&gt; Residual deviance: 13250  on 9997  degrees of freedom\n#&gt; AIC: 13256\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n# Add propensities to table\ndf_aug &lt;- membership %&gt;% mutate(propensity = predict(model_prop, type = \"response\"))\n\n# Extend data by IPW scores\ndf_ipw &lt;- df_aug %&gt;% mutate(\n  ipw = (card/propensity) + ((1-card) / (1-propensity)))\n\n# Look at data with IPW scores\ndf_ipw %&gt;% \n  select(card, age, pre_avg_purch, propensity, ipw)\n\n\n\n  \n\n\n# (2) Estimation\nmodel_ipw &lt;- lm(avg_purch ~ card,\n                data = df_ipw, \n                weights = ipw)\nsummary(model_ipw)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = df_ipw, weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -203.886  -29.009   -0.273   28.782  215.682 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  70.2627     0.4320  162.65   &lt;2e-16 ***\n#&gt; card         14.9548     0.6109   24.48   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 43.2 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.05654,    Adjusted R-squared:  0.05645 \n#&gt; F-statistic: 599.2 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n# \n# \n# # Plot histogram of estimated propensities\n# ggplot(df_aug, aes(x = propensity)) +\n#   geom_histogram(alpha = .3, color = \"blue\")\n# \n# # Looking for observations with highest weights\n# df_ipw %&gt;% \n#   select(card, age, pre_avg_purch, propensity, ipw) %&gt;% \n#   arrange(desc(ipw))\n# \n# # Run with high weights excluded\n# model_ipw_trim &lt;- lm(avg_purch ~ card,\n#                 data = df_ipw %&gt;% filter(propensity %&gt;% between(0.15, 0.85)),\n#                 weights = ipw)\n# summary(model_ipw_trim)"
  },
  {
    "objectID": "content/01_journal/09_iv.html#would-you-consider-the-naive-estimate-biased-and-if-yes-does-it-have-an-upward-or-downward-bias",
    "href": "content/01_journal/09_iv.html#would-you-consider-the-naive-estimate-biased-and-if-yes-does-it-have-an-upward-or-downward-bias",
    "title": "Instrumental Variables",
    "section": "4.2 . Would you consider the naive estimate biased, and if yes, does it have an upward or downward bias?",
    "text": "4.2 . Would you consider the naive estimate biased, and if yes, does it have an upward or downward bias?\nThe difference in estimates suggests that there might be unobserved confounding, and the naive estimate could be biased, potentially with an upward bias like in the given example regarding voluntary training program ."
  }
]